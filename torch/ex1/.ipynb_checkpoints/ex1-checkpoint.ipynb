{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'image'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data = torch.Tensor{\n",
    "{6.1101,17.592},\n",
    "{5.5277,9.1302},\n",
    "{8.5186,13.662},\n",
    "{7.0032,11.854},\n",
    "{5.8598,6.8233},\n",
    "{8.3829,11.886},\n",
    "{7.4764,4.3483},\n",
    "{8.5781,12},\n",
    "{6.4862,6.5987},\n",
    "{5.0546,3.8166},\n",
    "{5.7107,3.2522},\n",
    "{14.164,15.505},\n",
    "{5.734,3.1551},\n",
    "{8.4084,7.2258},\n",
    "{5.6407,0.71618},\n",
    "{5.3794,3.5129},\n",
    "{6.3654,5.3048},\n",
    "{5.1301,0.56077},\n",
    "{6.4296,3.6518},\n",
    "{7.0708,5.3893},\n",
    "{6.1891,3.1386},\n",
    "{20.27,21.767},\n",
    "{5.4901,4.263},\n",
    "{6.3261,5.1875},\n",
    "{5.5649,3.0825},\n",
    "{18.945,22.638},\n",
    "{12.828,13.501},\n",
    "{10.957,7.0467},\n",
    "{13.176,14.692},\n",
    "{22.203,24.147},\n",
    "{5.2524,-1.22},\n",
    "{6.5894,5.9966},\n",
    "{9.2482,12.134},\n",
    "{5.8918,1.8495},\n",
    "{8.2111,6.5426},\n",
    "{7.9334,4.5623},\n",
    "{8.0959,4.1164},\n",
    "{5.6063,3.3928},\n",
    "{12.836,10.117},\n",
    "{6.3534,5.4974},\n",
    "{5.4069,0.55657},\n",
    "{6.8825,3.9115},\n",
    "{11.708,5.3854},\n",
    "{5.7737,2.4406},\n",
    "{7.8247,6.7318},\n",
    "{7.0931,1.0463},\n",
    "{5.0702,5.1337},\n",
    "{5.8014,1.844},\n",
    "{11.7,8.0043},\n",
    "{5.5416,1.0179},\n",
    "{7.5402,6.7504},\n",
    "{5.3077,1.8396},\n",
    "{7.4239,4.2885},\n",
    "{7.6031,4.9981},\n",
    "{6.3328,1.4233},\n",
    "{6.3589,-1.4211},\n",
    "{6.2742,2.4756},\n",
    "{5.6397,4.6042},\n",
    "{9.3102,3.9624},\n",
    "{9.4536,5.4141},\n",
    "{8.8254,5.1694},\n",
    "{5.1793,-0.74279},\n",
    "{21.279,17.929},\n",
    "{14.908,12.054},\n",
    "{18.959,17.054},\n",
    "{7.2182,4.8852},\n",
    "{8.2951,5.7442},\n",
    "{10.236,7.7754},\n",
    "{5.4994,1.0173},\n",
    "{20.341,20.992},\n",
    "{10.136,6.6799},\n",
    "{7.3345,4.0259},\n",
    "{6.0062,1.2784},\n",
    "{7.2259,3.3411},\n",
    "{5.0269,-2.6807},\n",
    "{6.5479,0.29678},\n",
    "{7.5386,3.8845},\n",
    "{5.0365,5.7014},\n",
    "{10.274,6.7526},\n",
    "{5.1077,2.0576},\n",
    "{5.7292,0.47953},\n",
    "{5.1884,0.20421},\n",
    "{6.3557,0.67861},\n",
    "{9.7687,7.5435},\n",
    "{6.5159,5.3436},\n",
    "{8.5172,4.2415},\n",
    "{9.1802,6.7981},\n",
    "{6.002,0.92695},\n",
    "{5.5204,0.152},\n",
    "{5.0594,2.8214},\n",
    "{5.7077,1.8451},\n",
    "{7.6366,4.2959},\n",
    "{5.8707,7.2029},\n",
    "{5.3054,1.9869},\n",
    "{8.2934,0.14454},\n",
    "{13.394,9.0551},\n",
    "{5.4369,0.61705}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- reload the array\n",
    "file = torch.DiskFile('ex1data1.txt', 'r')\n",
    "data = file:readObject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "ninputs = 1; noutputs = 1\n",
    "model:add(nn.Linear(ninputs, noutputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, dl_dx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feval = function(x_new)\n",
    "   -- set x to x_new, if differnt\n",
    "   -- (in this simple example, x_new will typically always point to x,\n",
    "   -- so the copy is really useless)\n",
    "   if x ~= x_new then\n",
    "      x:copy(x_new)\n",
    "   end\n",
    "\n",
    "   -- select a new training sample\n",
    "   _nidx_ = (_nidx_ or 0) + 1\n",
    "   if _nidx_ > (#data)[1] then _nidx_ = 1 end\n",
    "\n",
    "   local sample = data[_nidx_]\n",
    "   local target = sample[{ {2} }]      -- this funny looking syntax allows\n",
    "   local inputs = sample[{ {1} }]    -- slicing of arrays.\n",
    "\n",
    "   -- reset gradients (gradients are always accumulated, to accommodate \n",
    "   -- batch methods)\n",
    "   dl_dx:zero()\n",
    "\n",
    "   -- evaluate the loss function and its derivative wrt x, for that sample\n",
    "   local loss_x = criterion:forward(model:forward(inputs), target)\n",
    "   model:backward(inputs, criterion:backward(model.output, target))\n",
    "\n",
    "   -- return loss(x) and dloss/dx\n",
    "   return loss_x, dl_dx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "   learningRate = 1e-4,\n",
    "   learningRateDecay = 1e-5,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1,1e4 do\n",
    "\n",
    "   -- this variable is used to estimate the average loss\n",
    "   current_loss = 0\n",
    "\n",
    "   -- an epoch is a full loop over our training data\n",
    "   for i = 1,(#data)[1] do\n",
    "\n",
    "      -- optim contains several optimization algorithms. \n",
    "      -- All of these algorithms assume the same parameters:\n",
    "      --   + a closure that computes the loss, and its gradient wrt to x, \n",
    "      --     given a point x\n",
    "      --   + a point x\n",
    "      --   + some parameters, which are algorithm-specific\n",
    "      \n",
    "      _,fs = optim.sgd(feval,x,sgd_params)\n",
    "\n",
    "      -- Functions in optim all return two things:\n",
    "      --   + the new x, found by the optimization method (here SGD)\n",
    "      --   + the value of the loss functions at all points that were used by\n",
    "      --     the algorithm. SGD only estimates the function once, so\n",
    "      --     that list just contains one value.\n",
    "\n",
    "      current_loss = current_loss + fs[1]\n",
    "   end\n",
    "\n",
    "   -- report average error on epoch\n",
    "   current_loss = current_loss / (#data)[1]\n",
    "   if i %100 == 0 then\n",
    "        print('current loss = ' .. current_loss)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- reload the array\n",
    "file = torch.DiskFile('ex1data2.txt', 'r')\n",
    "test = file:readObject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('id  approx   text')\n",
    "current_loss = 0\n",
    "for i = 1,(#test)[1] do\n",
    "   local myPrediction = model:forward(test[i][1])\n",
    "   print(string.format(\"%2d  %6.2f %6.2f\", i, myPrediction[1], test[i][2]))\n",
    "    current_loss = current_loss + (myPrediction[1] - test[i][2])*(myPrediction[1] - test[i][2])\n",
    "end\n",
    "current_loss = current_loss / (#test)[1]\n",
    "print('evaluation = ' .. current_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
