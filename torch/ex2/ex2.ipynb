{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model\n",
    "### reference\n",
    "- [demo](https://github.com/torch/demos/blob/master/logistic-regression/example-logistic-regression.lua)\n",
    "- [coursera lecture](https://github.com/didw/lecture/blob/master/machine-learning/machine-learning-ex2/ex2/ex2.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'csvigo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: ex2data1.txt\t\n",
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = csvigo.load{path='ex2data1.txt', mode='raw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = torch.Tensor{ loaded }[1]:t()[{{1,2}}]:t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = torch.Tensor{ loaded }[1]:t()[3] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = {}\n",
    "stdv = {}\n",
    "for i=1,2 do\n",
    "    mean[i] = data[{{},{i}}]:mean()\n",
    "    stdv[i] = data[{{},{i}}]:std()\n",
    "    data[{{},{i}}]:add(-mean[i])\n",
    "    data[{{},{i}}]:div(stdv[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linLayer = nn.Linear(2,2)\n",
    "softMaxLayer = nn.LogSoftMax()\n",
    "model = nn.Sequential()\n",
    "model:add(linLayer)\n",
    "model:add(nn.Sigmoid())\n",
    "model:add(softMaxLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model (using SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, dl_dx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feval = function(x_new)\n",
    "   if x ~= x_new then\n",
    "      x:copy(x_new)\n",
    "   end\n",
    "\n",
    "   _nidx_ = (_nidx_ or 0) + 1\n",
    "   if _nidx_ > (#data)[1] then _nidx_ = 1 end\n",
    "\n",
    "   local inputs = data[_nidx_]\n",
    "   local target = label[_nidx_]\n",
    "\n",
    "   dl_dx:zero()\n",
    "\n",
    "   local loss_x = criterion:forward(model:forward(inputs), target)\n",
    "   model:backward(inputs, criterion:backward(model.output, target))\n",
    "\n",
    "   return loss_x, dl_dx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "   learningRate = 1e-3,\n",
    "   learningRateDecay = 1e-4,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('============================================================')\n",
    "print('Training with SGD')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch = 100 of 1000 current loss = 0.63530930608779\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 200 of 1000 current loss = 0.59215649973138\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 300 of 1000 current loss = 0.56912134428907\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 400 of 1000 current loss = 0.55465762979904\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 500 of 1000 current loss = 0.54461204108006\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 600 of 1000 current loss = 0.53715093867064\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 700 of 1000 current loss = 0.53134109389978\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 800 of 1000 current loss = 0.5266563992714\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "epoch = 900 of 1000 current loss = 0.52277671061168\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1,epochs do\n",
    "   current_loss = 0\n",
    "   for i = 1,(#data)[1] do\n",
    "      _,fs = optim.sgd(feval,x,sgd_params)\n",
    "      current_loss = current_loss + fs[1]\n",
    "   end\n",
    "\n",
    "   current_loss = current_loss / (#data)[1]\n",
    "   if i % 100 == 0 then\n",
    "        print('epoch = ' .. i .. \n",
    "         ' of ' .. epochs .. \n",
    "         ' current loss = ' .. current_loss)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function maxIndex(a,b)\n",
    "    if a>=b then return 1\n",
    "    else return 2 end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predictOut(a, b)\n",
    "    local input = torch.Tensor(2)\n",
    "    input[1] = a\n",
    "    input[2] = b\n",
    "    local logProbs = model:forward(input)\n",
    "    local probs = torch.exp(logProbs)\n",
    "    local prob1, prob2 = probs[1], probs[2]\n",
    "    return maxIndex(prob1, prob2), prob1, prob2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = 0\n",
    "for i = 1, (#data)[1] do\n",
    "    local prediction = predictOut(data[i][1], data[i][2])\n",
    "    \n",
    "    -- print(prediction, label[i])\n",
    "    if prediction == label[i] then\n",
    "        corr = corr + 1\n",
    "    end\n",
    "end\n",
    "print (corr / (#data)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
